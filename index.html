<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>KNN-Algorithm by trisha87</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">KNN-Algorithm</h1>
      <h2 class="project-tagline">Machine learning using K-NN Algorithm</h2>
      <a href="https://github.com/trisha87/kNN-algo" class="btn">View on GitHub</a>
      <a href="https://github.com/trisha87/kNN-algo/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/trisha87/kNN-algo/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h3>
<a id="introduction" class="anchor" href="#introduction" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Introduction</h3>

<p>Most of the time, we love to ask for recommendation from our friends before experimenting new things. We usually start with those whose taste we feel we share and we deduce that we will like too. This is the basic intuition behind k-Nearest Neighbors Algorithm. Although this is perhaps one of the simplest machine learning algorithms, it is still used widely.  </p>

<h3>
<a id="detailed-design" class="anchor" href="#detailed-design" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Detailed Design</h3>

<p>Lets check how we can implement this algorithm using R.
First we will read the data and visualize using scatter plot.</p>

<div class="highlight highlight-source-r"><pre>   library(<span class="pl-smi">ggplot2</span>)
   <span class="pl-smi">knn.df</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>dummy_data.csv<span class="pl-pds">"</span></span>)
   head(<span class="pl-smi">knn.df</span>)
   <span class="pl-smi">knn.df</span><span class="pl-k">$</span><span class="pl-smi">Y</span> <span class="pl-k">&lt;-</span> <span class="pl-k">factor</span>(<span class="pl-smi">knn.df</span><span class="pl-k">$</span><span class="pl-smi">Y</span>)
   ggplot(<span class="pl-smi">knn.df</span>, aes(<span class="pl-v">x</span><span class="pl-k">=</span><span class="pl-smi">X1</span>, <span class="pl-v">y</span><span class="pl-k">=</span><span class="pl-smi">X2</span>, <span class="pl-v">shape</span><span class="pl-k">=</span><span class="pl-smi">Y</span>, <span class="pl-v">color</span><span class="pl-k">=</span><span class="pl-smi">Y</span>)) <span class="pl-k">+</span>
     geom_point()</pre></div>

<p><img src="https://raw.githubusercontent.com/trisha87/kNN-algo/gh-pages/images/knn-scatterplot.png" alt="knn-scatterplot"></p>

<p>Now we want to classify whether a new data(X1 and X2 given) will be assigned to 0 or 1 for Y. For this, we have to calculate the distance vector for this test data.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">dist.vectr</span> <span class="pl-k">&lt;-</span> fuction(<span class="pl-smi">knn.df</span>, <span class="pl-smi">testdata</span>)
{
  <span class="pl-smi">dist</span> <span class="pl-k">&lt;-</span> vector(, nrow(<span class="pl-smi">knn.df</span>))
  <span class="pl-k">for</span>(<span class="pl-smi">i</span> <span class="pl-k">in</span> <span class="pl-c1">1</span><span class="pl-k">:</span>nrow(<span class="pl-smi">knn.df</span>))
  {
    <span class="pl-smi">dist</span>[<span class="pl-smi">i</span>] <span class="pl-k">&lt;-</span> sqrt((<span class="pl-smi">knn.df</span>[<span class="pl-smi">i</span>, <span class="pl-s"><span class="pl-pds">'</span>X1<span class="pl-pds">'</span></span>] <span class="pl-k">-</span> <span class="pl-smi">testdata</span>[<span class="pl-c1">1</span>])<span class="pl-k">^</span><span class="pl-c1">2</span> <span class="pl-k">+</span> (<span class="pl-smi">knn.df</span>[<span class="pl-smi">i</span>, <span class="pl-s"><span class="pl-pds">'</span>X2<span class="pl-pds">'</span></span>] <span class="pl-k">-</span> <span class="pl-smi">testdata</span>[<span class="pl-c1">2</span>])<span class="pl-k">^</span><span class="pl-c1">2</span>)
  }
  <span class="pl-k">return</span>(<span class="pl-smi">dist</span>)
}</pre></div>

<p>Once we have distance vector ready, we will require another function which will return the nearest data point. First we will sort the distance vector and get the first k nearest entries</p>

<div class="highlight highlight-source-r"><pre><span class="pl-en">knn.points</span> <span class="pl-k">&lt;-</span> <span class="pl-k">function</span>(<span class="pl-smi">knn.df</span>, <span class="pl-v">k</span><span class="pl-k">=</span><span class="pl-c1">5</span>)
{
  <span class="pl-smi">dist</span> <span class="pl-k">&lt;-</span> dist.vectr(<span class="pl-smi">knn.df</span>, <span class="pl-smi">testdata</span>)
  <span class="pl-smi">indices</span> <span class="pl-k">&lt;-</span> order(<span class="pl-smi">dist</span>)[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-smi">k</span>]
  <span class="pl-smi">predicted.y</span> <span class="pl-k">&lt;-</span> ifelse(mean(<span class="pl-smi">knn.df</span>[<span class="pl-smi">indices</span>, <span class="pl-s"><span class="pl-pds">'</span>Y<span class="pl-pds">'</span></span>]) <span class="pl-k">&gt;</span> <span class="pl-c1">0.5</span>, <span class="pl-c1">1</span>, <span class="pl-c1">0</span>)
  <span class="pl-k">return</span>(<span class="pl-smi">predicted.y</span>)
}</pre></div>

<h3>
<a id="using-r-package" class="anchor" href="#using-r-package" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Using R Package</h3>

<p>If you prefer to not use the automatic generator, push a branch named <code>gh-pages</code> to your repository to create a page manually. In addition to supporting regular HTML content, GitHub Pages support Jekyll, a simple, blog aware static site generator. Jekyll makes it easy to create site-wide headers and footers without having to copy them across every page. It also offers intelligent blog support and other advanced templating features.</p>

<h3>
<a id="authors-and-contributors" class="anchor" href="#authors-and-contributors" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Authors and Contributors</h3>

<p>You can @mention a GitHub username to generate a link to their profile. The resulting <code>&lt;a&gt;</code> element will link to the contributor’s GitHub Profile. For example: In 2007, Chris Wanstrath (<a href="https://github.com/defunkt" class="user-mention">@defunkt</a>), PJ Hyett (<a href="https://github.com/pjhyett" class="user-mention">@pjhyett</a>), and Tom Preston-Werner (<a href="https://github.com/mojombo" class="user-mention">@mojombo</a>) founded GitHub.</p>

<h3>
<a id="support-or-contact" class="anchor" href="#support-or-contact" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Support or Contact</h3>

<p>Having trouble with Pages? Check out our <a href="https://help.github.com/pages">documentation</a> or <a href="https://github.com/contact">contact support</a> and we’ll help you sort it out.</p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/trisha87/kNN-algo">KNN-Algorithm</a> is maintained by <a href="https://github.com/trisha87">trisha87</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
